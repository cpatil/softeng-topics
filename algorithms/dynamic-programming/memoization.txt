A memoized function "remembers" the results corresponding to some set of
specific inputs. Subsequent calls with remembered inputs return the remembered
result rather than recalculating it, thus eliminating the primary cost of a call
with given parameters from all but the first call made to the function with
those parameters. The set of remembered associations may be a fixed-size set
controlled by a replacement algorithm or a fixed set, depending on the nature of
the function and its use. A function can only be memoized if it is referentially
transparent; that is, only if calling the function has exactly the same effect
as replacing that function call with its return value. (Special case exceptions
to this restriction exist, however.) While related to lookup tables, since
memoization often uses such tables in its implementation, memoization populates
its cache of results transparently on the fly, as needed, rather than in
advance.

Memoization is a way to lower a function's time cost in exchange for space cost;
that is, memoized functions become optimized for speed in exchange for a higher
use of computer memory space. The time/space "cost" of algorithms has a specific
name in computing: computational complexity. All functions have a computational
complexity in time (i.e. they take time to execute) and in space.

Although a spaceâ€“time tradeoff occurs (i.e., space used is speed gained), this
differs from some other optimizations that involve time-space trade-off, such as
strength reduction, in that memoization is a run-time rather than compile-time
optimization. Moreover, strength reduction potentially replaces a costly
operation such as multiplication with a less costly operation such as addition,
and the results in savings can be highly machine-dependent (non-portable across
machines), whereas memoization is a more machine-independent, cross-platform
strategy. 

Lookup-Table:

In computer science, a lookup table is an array that replaces runtime
computation with a simpler array indexing operation. The savings in processing
time can be significant, because retrieving a value from memory is often faster
than carrying out an "expensive" computation or input/output operation.[1] The
tables may be precalculated and stored in static program storage, calculated (or
"pre-fetched") as part of a program's initialization phase (memoization), or
even stored in hardware in application-specific platforms. Lookup tables are
also used extensively to validate input values by matching against a list of
valid (or invalid) items in an array and, in some programming languages, may
include pointer functions (or offsets to labels) to process the matching input.
FPGAs also make extensive use of reconfigurable, hardware-implemented, lookup
tables to provide programmable hardware functionality. 