Memory management is the functionality of an operating system which handles or
manages primary memory and moves processes back and forth between main memory
and disk during execution. Memory management keeps track of each and every
memory location, regardless of either it is allocated to some process or it is
free. It checks how much memory is to be allocated to processes. It decides
which process will get memory at what time. It tracks whenever some memory gets
freed or unallocated and correspondingly it updates the status.

Symbolic addresses

	The addresses used in a source code. The variable names, constants, and
	instruction labels are the basic elements of the symbolic address space.

Relative addresses

	At the time of compilation, a compiler converts symbolic addresses into
	relative addresses.

Physical addresses

	The loader generates these addresses at the time when a program is loaded
	into main memory.

The set of all logical addresses generated by a program is referred to as a
logical address space. The set of all physical addresses corresponding to these
logical addresses is referred to as a physical address space.

The runtime mapping from virtual to physical address is done by the memory
management unit (MMU) which is a hardware device. MMU uses following mechanism
to convert virtual address to physical address.

	The user program deals with virtual addresses; it never sees the real
	physical addresses.

Static vs Dynamic Loading

The choice between Static or Dynamic Loading is to be made at the time of
computer program being developed. If you have to load your program statically,
then at the time of compilation, the complete programs will be compiled and
linked without leaving any external program or module dependency. The linker
combines the object program with other necessary object modules into an absolute
program, which also includes logical addresses.

If you are writing a Dynamically loaded program, then your compiler will compile
the program and for all the modules which you want to include dynamically, only
references will be provided and rest of the work will be done at the time of
execution.

At the time of loading, with static loading, the absolute program (and data) is
loaded into memory in order for execution to start.

If you are using dynamic loading, dynamic routines of the library are stored on
a disk in relocatable form and are loaded into memory only when they are needed
by the program.

Swapping is a mechanism in which a process can be swapped temporarily out of
main memory (or move) to secondary storage (disk) and make that memory available
to other processes. At some later time, the system swaps back the process from
the secondary storage to main memory.

Though performance is usually affected by swapping process but it helps in
running multiple and big processes in parallel and that's the reason Swapping is
also known as a technique for memory compaction.

Memory Allocation

Main memory usually has two partitions −

    Low Memory − Operating system resides in this memory.

    High Memory − User processes are held in high memory.

Fragmentation

As processes are loaded and removed from memory, the free memory space is broken
into little pieces. It happens after sometimes that processes cannot be
allocated to memory blocks considering their small size and memory blocks
remains unused. 

	External fragmentation

		Total memory space is enough to satisfy a request or to reside a process
		in it, but it is not contiguous, so it cannot be used.		 	

	Internal fragmentation

		Memory block assigned to process is bigger. Some portion of memory is
		left unused, as it cannot be used by another process.

	External fragmentation can be reduced by compaction or shuffle memory
	contents to place all free memory together in one large block. To make
	compaction feasible, relocation should be dynamic.

	The internal fragmentation can be reduced by effectively assigning the
	smallest partition but large enough for the process.

Paging

A computer can address more memory than the amount physically installed on the
system. This extra memory is actually called virtual memory and it is a section
of a hard drive that's set up to emulate the computer's RAM. Paging technique
plays an important role in implementing virtual memory.

Paging is a memory management technique in which process address space is broken
into blocks of the same size called pages (size is power of 2, between 512 bytes
and 8192 bytes). The size of the process is measured in the number of pages.

Similarly, main memory is divided into small fixed-sized blocks of (physical)
memory called frames and the size of a frame is kept the same as that of a page
to have optimum utilization of the main memory and to avoid external
fragmentation.

When the system allocates a frame to any page, it translates this logical
address into a physical address and create entry into the page table to be used
throughout execution of the program.

When a process is to be executed, its corresponding pages are loaded into any
available memory frames. Suppose you have a program of 8Kb but your memory can
accommodate only 5Kb at a given point in time, then the paging concept will come
into picture. When a computer runs out of RAM, the operating system (OS) will
move idle or unwanted pages of memory to secondary memory to free up RAM for
other processes and brings them back when needed by the program.

Here is a list of advantages and disadvantages of paging −

    Paging reduces external fragmentation, but still suffer from internal
    fragmentation.

    Paging is simple to implement and assumed as an efficient memory management
    technique.

    Due to equal size of the pages and frames, swapping becomes very easy.

    Page table requires extra memory space, so may not be good for a system
    having small RAM.

Page address is called logical address and represented by page number and the
offset.

Frame address is called physical address and represented by a frame number and
the offset.

A data structure called page map table is used to keep track of the relation
between a page of a process to a frame in physical memory.

Segmentation

Segmentation is a memory management technique in which each job is divided into
several segments of different sizes, one for each module that contains pieces
that perform related functions. Each segment is actually a different logical
address space of the program.

When a process is to be executed, its corresponding segmentation are loaded into
non-contiguous memory though every segment is loaded into a contiguous block of
available memory.

Segmentation memory management works very similar to paging but here segments
are of variable-length where as in paging pages are of fixed size.

A program segment contains the program's main function, utility functions, data
structures, and so on. The operating system maintains a segment map table for
every process and a list of free memory blocks along with segment numbers, their
size and corresponding memory locations in main memory. For each segment, the
table stores the starting address of the segment and the length of the segment.
A reference to a memory location includes a value that identifies a segment and
an offset.